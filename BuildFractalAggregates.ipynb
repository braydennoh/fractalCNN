{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fractal aggregate building algorithm. Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def generate_fractal_aggregate(N, a):\n",
    "    occupied_positions = set()\n",
    "    seeds = []\n",
    "\n",
    "    # Start with seed 1 at the center of a 100x100x100 grid\n",
    "    seed1_pos = (50, 50, 50)  # Centered in a 100x100x100 grid\n",
    "    seeds.append(seed1_pos)\n",
    "    occupied_positions.add(seed1_pos)\n",
    "\n",
    "    # Seed 2 is placed randomly in one of the neighbor positions of seed 1\n",
    "    neighbors = get_neighbor_positions(seed1_pos, occupied_positions)\n",
    "    if not neighbors:\n",
    "        raise Exception(\"No available positions for seed 2.\")\n",
    "    seed2_pos = random.choice(neighbors)\n",
    "    seeds.append(seed2_pos)\n",
    "    occupied_positions.add(seed2_pos)\n",
    "\n",
    "    # For each subsequent seed\n",
    "    for i in range(3, N + 1):\n",
    "        # Compute the exponents for existing seeds\n",
    "        exponents = np.array([a * (j - i + 1) for j in range(1, i)])\n",
    "        p_j_unnormalized = np.exp(exponents)\n",
    "        # Handle potential numerical issues\n",
    "        if np.sum(p_j_unnormalized) == 0:\n",
    "            continue  # Skip this iteration if probabilities are invalid\n",
    "        # Normalize probabilities\n",
    "        p_j = p_j_unnormalized / np.sum(p_j_unnormalized)\n",
    "        # Select a seed index according to the probabilities\n",
    "        try:\n",
    "            j = np.random.choice(range(1, i), p=p_j)\n",
    "        except ValueError:\n",
    "            continue  # Skip if random choice fails\n",
    "        # Validate selected seed index\n",
    "        if j - 1 < 0 or j - 1 >= len(seeds):\n",
    "            continue\n",
    "        selected_seed_pos = seeds[j - 1]\n",
    "        # Find free neighbor positions\n",
    "        neighbors = get_neighbor_positions(selected_seed_pos, occupied_positions)\n",
    "        if not neighbors:\n",
    "            continue  # Skip if no free neighbor positions\n",
    "        # Randomly choose one free neighbor position\n",
    "        new_seed_pos = random.choice(neighbors)\n",
    "        seeds.append(new_seed_pos)\n",
    "        occupied_positions.add(new_seed_pos)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "def get_neighbor_positions(position, occupied_positions):\n",
    "    x, y, z = position\n",
    "    neighbors = []\n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dz in [-1, 0, 1]:\n",
    "                if dx == 0 and dy == 0 and dz == 0:\n",
    "                    continue  # Skip the current position\n",
    "                neighbor = (x + dx, y + dy, z + dz)\n",
    "                if neighbor not in occupied_positions and all(0 <= coord < 100 for coord in neighbor):\n",
    "                    neighbors.append(neighbor)\n",
    "    return neighbors\n",
    "\n",
    "def plot_3d_matrix(seeds):\n",
    "    \"\"\"\n",
    "    Plots the 3D fractal aggregate as a voxel grid.\n",
    "\n",
    "    Parameters:\n",
    "    seeds (list): List of seed positions in the aggregate.\n",
    "    \"\"\"\n",
    "    # Create a 3D matrix (100x100x100)\n",
    "    grid = np.zeros((100, 100, 100), dtype=bool)\n",
    "\n",
    "    for x, y, z in seeds:\n",
    "        grid[x, y, z] = True  # Mark occupied positions\n",
    "\n",
    "    # Plot the voxel grid\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.voxels(grid, edgecolor='none', alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    plt.show()\n",
    "\n",
    "def compute_correlation_dimension(coords):\n",
    "    \"\"\"\n",
    "    Computes the correlation dimension d2 using the Grassberger-Procaccia algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    coords (numpy.ndarray): Array of point coordinates (N x dim).\n",
    "\n",
    "    Returns:\n",
    "    float: Estimated correlation dimension d2.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    distances = pdist(coords)\n",
    "    # Exclude zero distances (shouldn't be any, but just in case)\n",
    "    distances = distances[distances > 0]\n",
    "    # Sort distances\n",
    "    distances.sort()\n",
    "    # Range of r values (log-spaced)\n",
    "    r_values = np.logspace(np.log10(distances[0]), np.log10(distances[-1]), num=100)\n",
    "    C_r = []\n",
    "    for r in r_values:\n",
    "        C = np.sum(distances < r) / len(distances)\n",
    "        C_r.append(C)\n",
    "    C_r = np.array(C_r)\n",
    "    # Take logarithms\n",
    "    log_r = np.log(r_values)\n",
    "    log_Cr = np.log(C_r)\n",
    "    # Linear fit in log-log scale over the linear region\n",
    "    # Determine the linear region by inspecting the derivative\n",
    "    derivatives = np.gradient(log_Cr) / np.gradient(log_r)\n",
    "    # Choose the region where the derivative is relatively constant\n",
    "    # For simplicity, we'll take the middle 80% of data points\n",
    "    fit_start = int(len(log_r) * 0.1)\n",
    "    fit_end = int(len(log_r) * 0.9)\n",
    "    slope, intercept = np.polyfit(log_r[fit_start:fit_end], log_Cr[fit_start:fit_end], 1)\n",
    "    d2 = slope\n",
    "    return d2, log_r, log_Cr\n",
    "\n",
    "def main():\n",
    "    N = 1000  # Number of seeds\n",
    "    a = 10   # Exponent parameter\n",
    "\n",
    "    seeds = generate_fractal_aggregate(N=N, a=a)\n",
    "\n",
    "    # Plot the 3D aggregate as a voxel grid\n",
    "    plot_3d_matrix(seeds)\n",
    "\n",
    "    # Prepare coordinates\n",
    "    positions_array = np.array(seeds)\n",
    "\n",
    "    # Compute correlation dimension for 3D aggregate\n",
    "    coords_3D = positions_array\n",
    "    d2_3D, log_r_3D, log_Cr_3D = compute_correlation_dimension(coords_3D)\n",
    "\n",
    "    print(f\"Correlation dimension for 3D aggregate: {d2_3D:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fractal aggregate building algorithm. Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_axis_projections(seeds, save_path, scale_factor=5):\n",
    "    \"\"\"\n",
    "    Saves the projections of the fractal aggregate along X, Y, and Z axes as grayscale pixelated images\n",
    "    with dynamically adjusted square boundaries and scaled for better visibility.\n",
    "\n",
    "    Parameters:\n",
    "    seeds (list): List of seed positions in the aggregate.\n",
    "    save_path (str): Directory to save the images.\n",
    "    scale_factor (int): Factor by which to scale the output images.\n",
    "    \"\"\"\n",
    "    positions_array = np.array(seeds)\n",
    "    x_coords = positions_array[:, 0]\n",
    "    y_coords = positions_array[:, 1]\n",
    "    z_coords = positions_array[:, 2]\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def create_and_crop_square_projection(x_coords, y_coords):\n",
    "        \"\"\"\n",
    "        Create a grayscale grid projection where pixel intensity reflects the stacking density,\n",
    "        and crop it to a square bounding box of the aggregate.\n",
    "        \"\"\"\n",
    "        # Determine the bounding box of the aggregate\n",
    "        x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
    "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
    "\n",
    "        # Compute the size of the bounding box\n",
    "        width = x_max - x_min + 1\n",
    "        height = y_max - y_min + 1\n",
    "\n",
    "        # Determine the size of the square\n",
    "        square_size = max(width, height)\n",
    "\n",
    "        # Create a square grid to count the stacking density\n",
    "        grid = np.zeros((square_size, square_size), dtype=int)\n",
    "\n",
    "        # Compute offsets to center the aggregate in the square grid\n",
    "        x_offset = (square_size - width) // 2\n",
    "        y_offset = (square_size - height) // 2\n",
    "\n",
    "        # Populate the grid with stacking counts\n",
    "        for x, y in zip(x_coords, y_coords):\n",
    "            grid[y - y_min + y_offset, x - x_min + x_offset] += 1\n",
    "\n",
    "        # Normalize the grid to grayscale (0-255)\n",
    "        max_density = np.max(grid)\n",
    "        if max_density > 0:\n",
    "            grid = (grid / max_density * 255).astype(np.uint8)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    def scale_image(grid, scale_factor):\n",
    "        \"\"\"\n",
    "        Scale the grayscale image using nearest-neighbor interpolation.\n",
    "\n",
    "        Parameters:\n",
    "        grid (np.ndarray): The grayscale grid to scale.\n",
    "        scale_factor (int): Factor by which to scale the image.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The scaled image as a grayscale array.\n",
    "        \"\"\"\n",
    "        image = Image.fromarray(grid, mode=\"L\")  # \"L\" mode for grayscale\n",
    "        scaled_image = image.resize(\n",
    "            (grid.shape[1] * scale_factor, grid.shape[0] * scale_factor),\n",
    "            resample=Image.NEAREST\n",
    "        )\n",
    "        return scaled_image\n",
    "\n",
    "    # XY Projection\n",
    "    xy_grid = create_and_crop_square_projection(x_coords, y_coords)\n",
    "    xy_image = scale_image(xy_grid, scale_factor)\n",
    "    xy_image.save(os.path.join(save_path, 'xy_projection.bmp'))\n",
    "\n",
    "    # XZ Projection\n",
    "    xz_grid = create_and_crop_square_projection(x_coords, z_coords)\n",
    "    xz_image = scale_image(xz_grid, scale_factor)\n",
    "    xz_image.save(os.path.join(save_path, 'xz_projection.bmp'))\n",
    "\n",
    "    # YZ Projection\n",
    "    yz_grid = create_and_crop_square_projection(y_coords, z_coords)\n",
    "    yz_image = scale_image(yz_grid, scale_factor)\n",
    "    yz_image.save(os.path.join(save_path, 'yz_projection.bmp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined directory and save the floc images. This will take few hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def iterate_parameters():\n",
    "    base_path = \"/Volumes/PortableSSD/flocfractal/data1/\"\n",
    "    os.makedirs(base_path, exist_ok=True)  # Ensure base directory exists\n",
    "\n",
    "    # Total dataset size\n",
    "    total_samples = 10000\n",
    "\n",
    "    # Define ranges for parameters\n",
    "    N_values = np.linspace(1000, 5000, int(np.sqrt(total_samples)), dtype=int)  # Linearly spaced N\n",
    "    a_values = np.logspace(-7, 3, int(np.sqrt(total_samples)))  # Logarithmically spaced a\n",
    "\n",
    "\n",
    "    # Generate combinations of N and a\n",
    "    parameter_grid = [(N, a) for N in N_values for a in a_values]\n",
    "    assert len(parameter_grid) == total_samples  # Ensure 10,000 combinations\n",
    "\n",
    "    # Iterate through combinations\n",
    "    for i, (N, a) in enumerate(parameter_grid, start=1):\n",
    "        save_path = os.path.join(base_path, str(i))\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # Generate fractal aggregate\n",
    "        seeds = generate_fractal_aggregate(N=N, a=a)\n",
    "\n",
    "        # Compute correlation dimension\n",
    "        positions_array = np.array(seeds)\n",
    "        d2_3D, _, _ = compute_correlation_dimension(positions_array)\n",
    "\n",
    "        # Save projections\n",
    "        save_axis_projections(seeds, save_path, scale_factor=10)\n",
    "\n",
    "        # Save d2_3D value and parameters\n",
    "        with open(os.path.join(save_path, 'correlation_dimension.txt'), 'w') as f:\n",
    "            f.write(f\"Parameters: N={N}, a={a}\\n\")\n",
    "            f.write(f\"Correlation dimension (d2_3D): {d2_3D:.4f}\\n\")\n",
    "\n",
    "    print(f\"Dataset of {total_samples} samples generated in {base_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iterate_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the fractals generated and make it blurry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def apply_gaussian_blur_and_save(source_path, target_path, blur_radius=10):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur to images in a dataset and save them to a new directory.\n",
    "\n",
    "    Parameters:\n",
    "    source_path (str): Path to the source dataset.\n",
    "    target_path (str): Path to save the blurred dataset.\n",
    "    blur_radius (int): Radius of the Gaussian blur.\n",
    "    \"\"\"\n",
    "    # Ensure the target directory exists\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    # Process each folder in the source dataset\n",
    "    for folder in sorted(os.listdir(source_path)):\n",
    "        source_folder_path = os.path.join(source_path, folder)\n",
    "        target_folder_path = os.path.join(target_path, folder)\n",
    "\n",
    "        if not os.path.isdir(source_folder_path):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        os.makedirs(target_folder_path, exist_ok=True)\n",
    "\n",
    "        # Process each BMP file in the folder\n",
    "        for image_file in ['xy_projection.bmp', 'xz_projection.bmp', 'yz_projection.bmp']:\n",
    "            source_image_path = os.path.join(source_folder_path, image_file)\n",
    "            target_image_path = os.path.join(target_folder_path, image_file)\n",
    "\n",
    "            if os.path.exists(source_image_path):\n",
    "                try:\n",
    "                    # Open the image, apply Gaussian blur, and save it\n",
    "                    with Image.open(source_image_path) as img:\n",
    "                        blurred_img = img.filter(ImageFilter.GaussianBlur(blur_radius))\n",
    "                        blurred_img.save(target_image_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {source_image_path}: {e}\")\n",
    "\n",
    "        # Copy the correlation_dimension.txt file\n",
    "        source_txt_path = os.path.join(source_folder_path, 'correlation_dimension.txt')\n",
    "        target_txt_path = os.path.join(target_folder_path, 'correlation_dimension.txt')\n",
    "        if os.path.exists(source_txt_path):\n",
    "            try:\n",
    "                with open(source_txt_path, 'r') as f_src, open(target_txt_path, 'w') as f_target:\n",
    "                    f_target.write(f_src.read())\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {source_txt_path}: {e}\")\n",
    "\n",
    "# Paths\n",
    "source_dataset_path = \"/Volumes/PortableSSD/flocfractal/data1/\"\n",
    "blurred_dataset_path = \"/Volumes/PortableSSD/flocfractal/data1blurry1/\"\n",
    "\n",
    "# Apply Gaussian blur to the dataset\n",
    "apply_gaussian_blur_and_save(source_dataset_path, blurred_dataset_path, blur_radius=4)\n",
    "\n",
    "print(\"Blurring complete. Blurred dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "\n",
    "def generate_fractal_aggregate(N, a):\n",
    "    occupied_positions = set()\n",
    "    seeds = []\n",
    "\n",
    "    # Start with seed 1 at the center of a 100x100x100 grid\n",
    "    seed1_pos = (50, 50, 50)  # Centered in a 100x100x100 grid\n",
    "    seeds.append(seed1_pos)\n",
    "    occupied_positions.add(seed1_pos)\n",
    "\n",
    "    # Seed 2 is placed randomly in one of the neighbor positions of seed 1\n",
    "    neighbors = get_neighbor_positions(seed1_pos, occupied_positions)\n",
    "    if not neighbors:\n",
    "        raise Exception(\"No available positions for seed 2.\")\n",
    "    seed2_pos = random.choice(neighbors)\n",
    "    seeds.append(seed2_pos)\n",
    "    occupied_positions.add(seed2_pos)\n",
    "\n",
    "    # For each subsequent seed\n",
    "    for i in range(3, N + 1):\n",
    "        # Compute the exponents for existing seeds\n",
    "        exponents = np.array([a * (j - i + 1) for j in range(1, i)])\n",
    "        p_j_unnormalized = np.exp(exponents)\n",
    "        # Handle potential numerical issues\n",
    "        if np.sum(p_j_unnormalized) == 0:\n",
    "            continue  # Skip this iteration if probabilities are invalid\n",
    "        # Normalize probabilities\n",
    "        p_j = p_j_unnormalized / np.sum(p_j_unnormalized)\n",
    "        # Select a seed index according to the probabilities\n",
    "        try:\n",
    "            j = np.random.choice(range(1, i), p=p_j)\n",
    "        except ValueError:\n",
    "            continue  # Skip if random choice fails\n",
    "        # Validate selected seed index\n",
    "        if j - 1 < 0 or j - 1 >= len(seeds):\n",
    "            continue\n",
    "        selected_seed_pos = seeds[j - 1]\n",
    "        # Find free neighbor positions\n",
    "        neighbors = get_neighbor_positions(selected_seed_pos, occupied_positions)\n",
    "        if not neighbors:\n",
    "            continue  # Skip if no free neighbor positions\n",
    "        # Randomly choose one free neighbor position\n",
    "        new_seed_pos = random.choice(neighbors)\n",
    "        seeds.append(new_seed_pos)\n",
    "        occupied_positions.add(new_seed_pos)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "def get_neighbor_positions(position, occupied_positions):\n",
    "    x, y, z = position\n",
    "    neighbors = []\n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dz in [-1, 0, 1]:\n",
    "                if dx == 0 and dy == 0 and dz == 0:\n",
    "                    continue  # Skip the current position\n",
    "                neighbor = (x + dx, y + dy, z + dz)\n",
    "                if neighbor not in occupied_positions and all(0 <= coord < 100 for coord in neighbor):\n",
    "                    neighbors.append(neighbor)\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def compute_correlation_dimension(coords):\n",
    "    \"\"\"\n",
    "    Computes the correlation dimension d2 using the Grassberger-Procaccia algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    coords (numpy.ndarray): Array of point coordinates (N x dim).\n",
    "\n",
    "    Returns:\n",
    "    float: Estimated correlation dimension d2.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    distances = pdist(coords)\n",
    "    # Exclude zero distances (shouldn't be any, but just in case)\n",
    "    distances = distances[distances > 0]\n",
    "    # Sort distances\n",
    "    distances.sort()\n",
    "    # Range of r values (log-spaced)\n",
    "    r_values = np.logspace(np.log10(distances[0]), np.log10(distances[-1]), num=100)\n",
    "    C_r = []\n",
    "    for r in r_values:\n",
    "        C = np.sum(distances < r) / len(distances)\n",
    "        C_r.append(C)\n",
    "    C_r = np.array(C_r)\n",
    "    # Take logarithms\n",
    "    log_r = np.log(r_values)\n",
    "    log_Cr = np.log(C_r)\n",
    "    # Linear fit in log-log scale over the linear region\n",
    "    # Determine the linear region by inspecting the derivative\n",
    "    derivatives = np.gradient(log_Cr) / np.gradient(log_r)\n",
    "    # Choose the region where the derivative is relatively constant\n",
    "    # For simplicity, we'll take the middle 80% of data points\n",
    "    fit_start = int(len(log_r) * 0.1)\n",
    "    fit_end = int(len(log_r) * 0.9)\n",
    "    slope, intercept = np.polyfit(log_r[fit_start:fit_end], log_Cr[fit_start:fit_end], 1)\n",
    "    d2 = slope\n",
    "    return d2, log_r, log_Cr\n",
    "\n",
    "def display_axis_projections(seeds, scale_factor=5):\n",
    "    \"\"\"\n",
    "    Displays the projections of the fractal aggregate along X, Y, and Z axes.\n",
    "\n",
    "    Parameters:\n",
    "    seeds (list): List of seed positions in the aggregate.\n",
    "    scale_factor (int): Factor by which to scale the output images.\n",
    "    \"\"\"\n",
    "    positions_array = np.array(seeds)\n",
    "    x_coords = positions_array[:, 0]\n",
    "    y_coords = positions_array[:, 1]\n",
    "    z_coords = positions_array[:, 2]\n",
    "\n",
    "    def create_and_crop_square_projection(x_coords, y_coords):\n",
    "        \"\"\"\n",
    "        Create a grayscale grid projection where pixel intensity reflects the stacking density,\n",
    "        and crop it to a square bounding box of the aggregate.\n",
    "        \"\"\"\n",
    "        # Determine the bounding box of the aggregate\n",
    "        x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
    "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
    "\n",
    "        # Compute the size of the bounding box\n",
    "        width = x_max - x_min + 1\n",
    "        height = y_max - y_min + 1\n",
    "\n",
    "        # Determine the size of the square\n",
    "        square_size = max(width, height)\n",
    "\n",
    "        # Create a square grid to count the stacking density\n",
    "        grid = np.zeros((square_size, square_size), dtype=int)\n",
    "\n",
    "        # Compute offsets to center the aggregate in the square grid\n",
    "        x_offset = (square_size - width) // 2\n",
    "        y_offset = (square_size - height) // 2\n",
    "\n",
    "        # Populate the grid with stacking counts\n",
    "        for x, y in zip(x_coords, y_coords):\n",
    "            grid[y - y_min + y_offset, x - x_min + x_offset] += 1\n",
    "\n",
    "        # Normalize the grid to grayscale (0-255)\n",
    "        max_density = np.max(grid)\n",
    "        if max_density > 0:\n",
    "            grid = (grid / max_density * 255).astype(np.uint8)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    def scale_image(grid, scale_factor):\n",
    "        \"\"\"\n",
    "        Scale the grayscale image using nearest-neighbor interpolation.\n",
    "\n",
    "        Parameters:\n",
    "        grid (np.ndarray): The grayscale grid to scale.\n",
    "        scale_factor (int): Factor by which to scale the image.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The scaled image as a grayscale array.\n",
    "        \"\"\"\n",
    "        image = Image.fromarray(grid, mode=\"L\")  # \"L\" mode for grayscale\n",
    "        scaled_image = image.resize(\n",
    "            (grid.shape[1] * scale_factor, grid.shape[0] * scale_factor),\n",
    "            resample=Image.NEAREST\n",
    "        )\n",
    "        return scaled_image\n",
    "\n",
    "    # XY Projection\n",
    "    xy_grid = create_and_crop_square_projection(x_coords, y_coords)\n",
    "    xy_image = scale_image(xy_grid, scale_factor)\n",
    "\n",
    "    # XZ Projection\n",
    "    xz_grid = create_and_crop_square_projection(x_coords, z_coords)\n",
    "    xz_image = scale_image(xz_grid, scale_factor)\n",
    "\n",
    "    # YZ Projection\n",
    "    yz_grid = create_and_crop_square_projection(y_coords, z_coords)\n",
    "    yz_image = scale_image(yz_grid, scale_factor)\n",
    "\n",
    "    # Display Projections\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes[0].imshow(xy_image, cmap='gray')\n",
    "    axes[0].set_title(\"XY Projection\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(xz_image, cmap='gray')\n",
    "    axes[1].set_title(\"XZ Projection\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(yz_image, cmap='gray')\n",
    "    axes[2].set_title(\"YZ Projection\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_3d_matrix(seeds):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.axis(\"off\")  # Turn off the axes for better visualization\n",
    "\n",
    "    # Define sphere parameters\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "    for x, y, z in seeds:\n",
    "        # Generate sphere surface\n",
    "        sphere_x = 0.8 * np.outer(np.cos(u), np.sin(v)) + x\n",
    "        sphere_y = 0.8 * np.outer(np.sin(u), np.sin(v)) + y\n",
    "        sphere_z = 0.8 * np.outer(np.ones(np.size(u)), np.cos(v)) + z\n",
    "\n",
    "        # Use shading for lighting effect without outlines\n",
    "        color_map = np.sqrt((sphere_x - x)**2 + (sphere_y - y)**2 + (sphere_z - (z + 0.5))**2)\n",
    "        ax.plot_surface(sphere_x, sphere_y, sphere_z, facecolors=plt.cm.gray_r(color_map / color_map.max()),\n",
    "                        rstride=5, cstride=5, antialiased=True, linewidth=0)\n",
    "\n",
    "    # Ensure the aspect ratio is equal\n",
    "    max_range = np.array([np.ptp([s[0] for s in seeds]), \n",
    "                          np.ptp([s[1] for s in seeds]), \n",
    "                          np.ptp([s[2] for s in seeds])]).max()\n",
    "    mid_x = np.mean([s[0] for s in seeds])\n",
    "    mid_y = np.mean([s[1] for s in seeds])\n",
    "    mid_z = np.mean([s[2] for s in seeds])\n",
    "\n",
    "    ax.set_xlim(mid_x - max_range / 2, mid_x + max_range / 2)\n",
    "    ax.set_ylim(mid_y - max_range / 2, mid_y + max_range / 2)\n",
    "    ax.set_zlim(mid_z - max_range / 2, mid_z + max_range / 2)\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    N = 1000  # Number of seeds\n",
    "    a = 10   # Exponent parameter\n",
    "\n",
    "    seeds = generate_fractal_aggregate(N=N, a=a)\n",
    "\n",
    "    # Plot the 3D aggregate as a voxel grid\n",
    "    plot_3d_matrix(seeds)\n",
    "\n",
    "    # Display projections of the fractal aggregate along the axes\n",
    "    display_axis_projections(seeds)\n",
    "\n",
    "    # Prepare coordinates\n",
    "    positions_array = np.array(seeds)\n",
    "\n",
    "    # Compute correlation dimension for 3D aggregate\n",
    "    coords_3D = positions_array\n",
    "    d2_3D, log_r_3D, log_Cr_3D = compute_correlation_dimension(coords_3D)\n",
    "\n",
    "    print(f\"Correlation dimension for 3D aggregate: {d2_3D:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_matrix(seeds, output_dir):\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.axis(\"off\")  # Turn off the axes for better visualization\n",
    "\n",
    "    # Define sphere parameters\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "    for x, y, z in seeds:\n",
    "        # Generate sphere surface\n",
    "        sphere_x = 0.8 * np.outer(np.cos(u), np.sin(v)) + x\n",
    "        sphere_y = 0.8 * np.outer(np.sin(u), np.sin(v)) + y\n",
    "        sphere_z = 0.8 * np.outer(np.ones(np.size(u)), np.cos(v)) + z\n",
    "\n",
    "        # Use shading for lighting effect without outlines\n",
    "        color_map = np.sqrt((sphere_x - x)**2 + (sphere_y - y)**2 + (sphere_z - (z + 0.5))**2)\n",
    "        ax.plot_surface(sphere_x, sphere_y, sphere_z, facecolors=plt.cm.gray_r(color_map / color_map.max()),\n",
    "                        rstride=5, cstride=5, antialiased=True, linewidth=0)\n",
    "\n",
    "    # Ensure the aspect ratio is equal\n",
    "    max_range = np.array([np.ptp([s[0] for s in seeds]), \n",
    "                          np.ptp([s[1] for s in seeds]), \n",
    "                          np.ptp([s[2] for s in seeds])]).max()\n",
    "    mid_x = np.mean([s[0] for s in seeds])\n",
    "    mid_y = np.mean([s[1] for s in seeds])\n",
    "    mid_z = np.mean([s[2] for s in seeds])\n",
    "\n",
    "    ax.set_xlim(mid_x - max_range / 2, mid_x + max_range / 2)\n",
    "    ax.set_ylim(mid_y - max_range / 2, mid_y + max_range / 2)\n",
    "    ax.set_zlim(mid_z - max_range / 2, mid_z + max_range / 2)\n",
    "\n",
    "    # Rotate and save images at 45-degree intervals\n",
    "    for angle in range(0, 360, 45):\n",
    "        ax.view_init(elev=20, azim=angle)\n",
    "        file_name = f\"{output_dir}/3d_plot_{angle}.png\"\n",
    "        plt.savefig(file_name, dpi=300)\n",
    "        print(f\"Saved {file_name}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def main():\n",
    "    N = 1000  # Number of seeds\n",
    "    a = 10    # Exponent parameter\n",
    "    output_dir = \"/Users/braydennoh/Downloads\"\n",
    "\n",
    "    seeds = generate_fractal_aggregate(N=N, a=a)\n",
    "\n",
    "    # Save rotating 3D plots\n",
    "    plot_3d_matrix(seeds, output_dir)\n",
    "\n",
    "    # Display projections of the fractal aggregate along the axes\n",
    "    display_axis_projections(seeds)\n",
    "\n",
    "    # Prepare coordinates\n",
    "    positions_array = np.array(seeds)\n",
    "\n",
    "    # Compute correlation dimension for 3D aggregate\n",
    "    coords_3D = positions_array\n",
    "    d2_3D, log_r_3D, log_Cr_3D = compute_correlation_dimension(coords_3D)\n",
    "\n",
    "    print(f\"Correlation dimension for 3D aggregate: {d2_3D:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
